# Лабораторная работа: Оценка факторов биоразнообразия регионов
## Архитектура, математические модели и блок-схемы

---

## 1. ПОСТАНОВКА ЗАДАЧИ

### 1.1 Цель проекта
Разработать систему машинного обучения для анализа и прогнозирования биоразнообразия регионов на основе климатических и антропогенных факторов.

### 1.2 Бизнес-задачи
- Выявить ключевые факторы, влияющие на биоразнообразие
- Построить прогнозную модель для оценки биоразнообразия
- Создать географическую визуализацию распределения биоразнообразия
- Предоставить рекомендации по сохранению биоразнообразия

### 1.3 Технические задачи
- EDA (Exploratory Data Analysis) и предобработка данных
- Feature Engineering для создания синтетических признаков
- Обучение минимум 3 регрессионных моделей различных типов
- Оценка качества моделей (R², RMSE, MAE, Cross-Validation)
- Интерпретация результатов и визуализация

---

## 2. АРХИТЕКТУРА СИСТЕМЫ

### 2.1 Общая архитектура

```
┌─────────────────────────────────────────────────────────────────┐
│                     DATA PIPELINE                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐      ┌──────────────┐      ┌──────────────┐   │
│  │   Raw Data   │ ───> │     EDA      │ ───> │Preprocessing │   │
│  │   (WB_GBIOD) │      │  & Analysis  │      │ & Feature Eng│   │
│  └──────────────┘      └──────────────┘      └──────────────┘   │
│                                                      │          │
└──────────────────────────────────────────────────────┼──────────┘
                                                       │
                                                       v
┌─────────────────────────────────────────────────────────────────┐
│                   MODELING PIPELINE                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌────────────────┐    ┌────────────────┐    ┌──────────────-┐  │
│  │ Linear Models  │    │ Ensemble Models│    │Boosting Models│  │
│  │ - Linear Reg   │    │ - Random Forest│    │ - XGBoost     │  │
│  │ - Ridge        │    │ - Extra Trees  │    │ - GradBoost   │  │
│  │ - Lasso        │    │                │    │ - CatBoost    │  │
│  └────────────────┘    └────────────────┘    └──────────────-┘  │
│          │                     │                      │         │
│          └─────────────────────┴──────────────────────┘         │
│                                │                                │
└────────────────────────────────┼────────────────────────────────┘
                                 v
┌─────────────────────────────────────────────────────────────────┐
│                  EVALUATION & VISUALIZATION                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────────┐   │
│  │   Metrics    │    │Feature Import│    │  Geo Visualiz.   │   │
│  │ - R²         │    │- SHAP values │    │- Choropleth maps │   │
│  │ - RMSE       │    │- Importance  │    │- Interactive viz │   │
│  │ - MAE        │    │- Correlation │    │- Plotly/Folium   │   │
│  │ - CV Scores  │    │              │    │                  │   │
│  └──────────────┘    └──────────────┘    └──────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 Модульная структура

```
project/
│
├── data/
│   ├── raw/                    # Исходные данные
│   ├── processed/              # Обработанные данные
│   └── external/               # Внешние данные (климат, демография)
│
├── notebooks/
│   ├── 01_eda.ipynb           # Exploratory Data Analysis
│   ├── 02_preprocessing.ipynb  # Предобработка данных
│   ├── 03_modeling.ipynb       # Моделирование
│   └── 04_evaluation.ipynb     # Оценка и визуализация
│
├── src/
│   ├── data/
│   │   ├── loader.py           # Загрузка данных
│   │   └── preprocessor.py     # Предобработка
│   ├── features/
│   │   └── engineering.py      # Feature engineering
│   ├── models/
│   │   ├── linear_models.py    # Линейные модели
│   │   ├── ensemble_models.py  # Ансамблевые модели
│   │   └── boosting_models.py  # Бустинговые модели
│   ├── evaluation/
│   │   └── metrics.py          # Метрики и оценка
│   └── visualization/
│       ├── plots.py            # Графики
│       └── maps.py             # Географические карты
│
├── models/                     # Сохраненные модели
├── reports/                    # Отчеты и результаты
└── requirements.txt            # Зависимости
```

---

## 3. БЛОК-СХЕМА ПРОЦЕССА

### 3.1 Основной процесс

```
                    ┌─────────────────┐
                    │   START         │
                    └────────┬────────┘
                             │
                             v
                    ┌─────────────────┐
                    │ Load Raw Data   │
                    │ (WB_GBIOD.csv)  │
                    └────────┬────────┘
                             │
                             v
                    ┌─────────────────┐
                    │  Pivot Data by  │
                    │   Indicators    │
                    └────────┬────────┘
                             │
                             v
                    ┌─────────────────┐
                    │  Add External   │
                    │    Features     │
                    │ (Climate, Demo) │
                    └────────┬────────┘
                             │
                             v
                    ┌─────────────────┐
                    │ Create Target   │
                    │   Variable      │
                    │(Biodiversity Idx)│
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              │                             │
              v                             v
     ┌────────────────┐          ┌─────────────────┐
     │   Handle       │          │   Outlier       │
     │  Missing Data  │          │   Detection     │
     └────────┬───────┘          └────────┬────────┘
              │                           │
              └──────────┬────────────────┘
                         │
                         v
                ┌────────────────┐
                │   Split Data   │
                │ (Train/Test)   │
                └────────┬───────┘
                         │
                         v
                ┌────────────────┐
                │  Normalize/    │
                │  Scale Data    │
                └────────┬───────┘
                         │
         ┌───────────────┼───────────────┐
         │               │               │
         v               v               v
  ┌──────────┐   ┌──────────┐   ┌──────────┐
  │ Linear   │   │ Ensemble │   │ Boosting │
  │ Models   │   │ Models   │   │ Models   │
  └─────┬────┘   └─────┬────┘   └─────┬────┘
        │              │              │
        └──────────────┼──────────────┘
                       │
                       v
              ┌────────────────┐
              │   Evaluate     │
              │    Models      │
              │(R², RMSE, MAE) │
              └────────┬───────┘
                       │
                       v
              ┌────────────────┐
              │  Select Best   │
              │     Model      │
              └────────┬───────┘
                       │
                       v
              ┌────────────────┐
              │  Visualize     │
              │   Results      │
              └────────┬───────┘
                       │
                       v
              ┌────────────────┐
              │  Generate      │
              │   Report       │
              └────────┬───────┘
                       │
                       v
              ┌────────────────┐
              │     END        │
              └────────────────┘
```

### 3.2 Блок-схема предобработки данных

```
┌────────────────────┐
│  Input: Raw Data   │
└──────────┬─────────┘
           │
           v
┌────────────────────┐
│ Check Data Quality │
│ - Shape            │
│ - Types            │
│ - Missing values   │
└──────────┬─────────┘
           │
           v
      ┌────┴────┐
      │ Missing │
      │ Values? │
      └────┬────┘
      Yes  │  No
      ┌────┴────┐
      │         │
      v         v
┌─────────┐  ┌─────────┐
│ Impute  │  │Continue │
│ Median/ │  │         │
│  Mean   │  │         │
└────┬────┘  └────┬────┘
     │            │
     └──────┬─────┘
            │
            v
     ┌──────────────┐
     │   Outlier    │
     │  Detection   │
     │ (IQR Method) │
     └──────┬───────┘
            │
            v
     ┌──────────────┐
     │ Q1 = P25     │
     │ Q3 = P75     │
     │ IQR = Q3-Q1  │
     └──────┬───────┘
            │
            v
     ┌──────────────┐
     │ Lower = Q1   │
     │   - 1.5*IQR  │
     │ Upper = Q3   │
     │   + 1.5*IQR  │
     └──────┬───────┘
            │
            v
     ┌──────────────┐
     │Clip outliers │
     │ to bounds    │
     └──────┬───────┘
            │
            v
     ┌──────────────┐
     │ Normalize    │
     │(RobustScaler)│
     └──────┬───────┘
            │
            v
     ┌──────────────┐
     │Output: Clean │
     │    Data      │
     └──────────────┘
```

---

## 4. МАТЕМАТИЧЕСКИЕ ФОРМУЛИРОВКИ

### 4.1 Целевая переменная (Biodiversity Index)

**Синтетический индекс биоразнообразия:**

```
BI = w₁·FC + w₂·PA + w₃·AR + w₄·(100-UR) + N(μ, σ)
```

где:
- `BI` - Biodiversity Index (индекс биоразнообразия)
- `FC` - Forest Cover (лесной покров, %)
- `PA` - Protected Areas (защищенные территории, %)
- `AR` - Annual Rainfall (годовые осадки, мм/100)
- `UR` - Urbanization Rate (уровень урбанизации, %)
- `w₁=0.3, w₂=0.2, w₃=0.01, w₄=0.2` - веса
- `N(μ, σ)` - нормальный шум с μ=100, σ=50

**Альтернатива (если есть данные о видах):**

```
BI = Σ(Species_i) + Endemic_Species_Weight
```

### 4.2 Обнаружение выбросов (IQR Method)

```
Q₁ = Percentile₂₅(X)
Q₃ = Percentile₇₅(X)
IQR = Q₃ - Q₁

Lower_Bound = Q₁ - k·IQR
Upper_Bound = Q₃ + k·IQR

X_clipped = {
    Lower_Bound,    if X < Lower_Bound
    Upper_Bound,    if X > Upper_Bound
    X,              otherwise
}
```

где `k = 1.5` (стандартный множитель)

### 4.3 Нормализация (Robust Scaler)

```
X_scaled = (X - median(X)) / IQR(X)
```

где:
- `median(X)` - медиана признака
- `IQR(X) = Q₃ - Q₁` - межквартильный размах

**Преимущества Robust Scaler:**
- Устойчив к выбросам
- Сохраняет структуру данных
- Не требует нормального распределения

---

## 5. РЕГРЕССИОННЫЕ МОДЕЛИ

### 5.1 Linear Regression (Линейная регрессия)

**Математическая формулировка:**

```
y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε
```

где:
- `y` - целевая переменная (Biodiversity Index)
- `xᵢ` - признаки (температура, лесной покров и т.д.)
- `βᵢ` - коэффициенты модели
- `ε` - ошибка

**Метод наименьших квадратов (OLS):**

```
β = (XᵀX)⁻¹Xᵀy
```

**Функция потерь (MSE):**

```
L(β) = (1/n) Σᵢ₌₁ⁿ (yᵢ - ŷᵢ)²
```

**Преимущества:**
- Простота и интерпретируемость
- Быстрое обучение
- Хорошо работает на линейных зависимостях

**Недостатки:**
- Предполагает линейность
- Чувствительна к выбросам
- Может переобучаться при большом количестве признаков

### 5.2 Ridge Regression (Гребневая регрессия)

**Математическая формулировка:**

```
L(β) = (1/n) Σᵢ₌₁ⁿ (yᵢ - ŷᵢ)² + α Σⱼ₌₁ᵖ βⱼ²
```

где:
- `α` - параметр регуляризации (penalty)
- L2-регуляризация: `Σⱼ₌₁ᵖ βⱼ²`

**Решение:**

```
β = (XᵀX + αI)⁻¹Xᵀy
```

**Преимущества:**
- Уменьшает переобучение
- Работает с мультиколлинеарностью
- Стабильнее линейной регрессии

### 5.3 Random Forest Regressor

**Алгоритм:**

```
1. Для b = 1 to B:
   a) Взять bootstrap-выборку данных
   b) Построить дерево решений:
      - На каждом узле выбрать m случайных признаков
      - Найти лучшее разбиение по MSE
      - Продолжить рекурсивно
2. Финальное предсказание:
   ŷ = (1/B) Σᵦ₌₁ᴮ ŷᵦ
```

**Критерий разбиения (MSE):**

```
MSE = (1/n) Σᵢ∈node (yᵢ - ȳnode)²
```

**Важность признака:**

```
Importance(xⱼ) = (1/B) Σᵦ₌₁ᴮ Σt∈Tᵦ I(split_on_xⱼ) · ΔMSEₜ
```

**Параметры:**
- `n_estimators` - количество деревьев (100-500)
- `max_depth` - максимальная глубина дерева (10-20)
- `min_samples_split` - минимум для разбиения узла (2-10)
- `min_samples_leaf` - минимум в листе (1-5)

**Преимущества:**
- Высокая точность
- Устойчивость к переобучению
- Работает с нелинейными зависимостями
- Не требует нормализации
- Оценка важности признаков

### 5.4 XGBoost (Extreme Gradient Boosting)

**Математическая формулировка:**

```
ŷᵢ⁽ᵗ⁾ = ŷᵢ⁽ᵗ⁻¹⁾ + ηfₜ(xᵢ)
```

где:
- `t` - номер итерации
- `η` - learning rate (скорость обучения)
- `fₜ` - новое дерево на итерации t

**Функция потерь:**

```
L⁽ᵗ⁾ = Σᵢ₌₁ⁿ l(yᵢ, ŷᵢ⁽ᵗ⁻¹⁾ + fₜ(xᵢ)) + Ω(fₜ)
```

где:
- `l(yᵢ, ŷᵢ)` - функция потерь (MSE для регрессии)
- `Ω(fₜ) = γT + (λ/2)Σⱼ₌₁ᵀ wⱼ²` - регуляризация

**Градиентная аппроксимация (Taylor expansion):**

```
L⁽ᵗ⁾ ≈ Σᵢ₌₁ⁿ [l(yᵢ, ŷᵢ⁽ᵗ⁻¹⁾) + gᵢfₜ(xᵢ) + (1/2)hᵢfₜ²(xᵢ)] + Ω(fₜ)
```

где:
- `gᵢ = ∂ŷ⁽ᵗ⁻¹⁾l(yᵢ, ŷᵢ⁽ᵗ⁻¹⁾)` - первая производная
- `hᵢ = ∂²ŷ⁽ᵗ⁻¹⁾l(yᵢ, ŷᵢ⁽ᵗ⁻¹⁾)` - вторая производная

**Оптимальный вес листа:**

```
wⱼ* = -Gⱼ / (Hⱼ + λ)
```

где:
- `Gⱼ = Σᵢ∈Iⱼ gᵢ` - сумма градиентов
- `Hⱼ = Σᵢ∈Iⱼ hᵢ` - сумма гессианов

**Gain для разбиения:**

```
Gain = (GL² / (HL + λ)) + (GR² / (HR + λ)) - ((GL+GR)² / (HL+HR + λ)) - γ
```

**Параметры:**
- `n_estimators` - количество деревьев (100-1000)
- `learning_rate` (η) - скорость обучения (0.01-0.3)
- `max_depth` - глубина деревьев (3-10)
- `min_child_weight` - минимальный вес в листе
- `subsample` - доля примеров для обучения (0.5-1.0)
- `colsample_bytree` - доля признаков (0.5-1.0)
- `gamma` (γ) - минимальный gain для разбиения
- `lambda` (λ) - L2 регуляризация

**Преимущества:**
- Высокая точность
- Эффективное использование памяти
- Параллельное обучение
- Встроенная регуляризация
- Обработка пропущенных значений

### 5.5 Gradient Boosting Regressor

**Алгоритм:**

```
1. Инициализация: F₀(x) = argmin_γ Σᵢ₌₁ⁿ L(yᵢ, γ)
2. Для m = 1 to M:
   a) Вычислить псевдо-остатки:
      rᵢₘ = -[∂L(yᵢ, F(xᵢ))/∂F(xᵢ)]|F=Fₘ₋₁
   b) Обучить дерево hₘ(x) на (xᵢ, rᵢₘ)
   c) Найти оптимальный γₘ:
      γₘ = argmin_γ Σᵢ₌₁ⁿ L(yᵢ, Fₘ₋₁(xᵢ) + γhₘ(xᵢ))
   d) Обновить модель:
      Fₘ(x) = Fₘ₋₁(x) + ν·γₘhₘ(x)
3. Вывод: F(x) = Fₘ(x)
```

где:
- `ν` - learning rate (скорость обучения)
- `M` - количество итераций

**Для MSE:**

```
rᵢₘ = yᵢ - Fₘ₋₁(xᵢ)
```

**Параметры:**
- `n_estimators` - количество итераций
- `learning_rate` - скорость обучения
- `max_depth` - глубина деревьев
- `min_samples_split` - минимум для разбиения
- `subsample` - стохастический градиентный спуск

---

## 6. МЕТРИКИ ОЦЕНКИ

### 6.1 R² Score (Coefficient of Determination)

```
R² = 1 - (SS_res / SS_tot)

где:
SS_res = Σᵢ₌₁ⁿ (yᵢ - ŷᵢ)²    (остаточная сумма квадратов)
SS_tot = Σᵢ₌₁ⁿ (yᵢ - ȳ)²     (общая сумма квадратов)
```

**Интерпретация:**
- R² = 1: идеальное предсказание
- R² = 0: модель не лучше среднего
- R² < 0: модель хуже среднего

### 6.2 RMSE (Root Mean Squared Error)

```
RMSE = √[(1/n) Σᵢ₌₁ⁿ (yᵢ - ŷᵢ)²]
```

**Свойства:**
- Чувствителен к выбросам
- В тех же единицах, что и целевая переменная
- Штрафует большие ошибки сильнее

### 6.3 MAE (Mean Absolute Error)

```
MAE = (1/n) Σᵢ₌₁ⁿ |yᵢ - ŷᵢ|
```

**Свойства:**
- Устойчив к выбросам
- Легко интерпретируется
- Линейная шкала ошибок

### 6.4 Cross-Validation Score

**K-Fold Cross-Validation:**

```
1. Разбить данные на K частей (фолдов)
2. Для каждого фолда k = 1 to K:
   - Обучить модель на K-1 фолдах
   - Оценить на k-м фолде
   - Сохранить score_k
3. CV_Score = (1/K) Σₖ₌₁ᴷ score_k
```

**Преимущества:**
- Более надежная оценка обобщающей способности
- Использует все данные для обучения и тестирования
- Уменьшает вариативность оценки

---

## 7. ВАЖНОСТЬ ПРИЗНАКОВ

### 7.1 Feature Importance (Random Forest / XGBoost)

**Для деревьев решений:**

```
Importance(xⱼ) = Σₜ∈all_nodes I(split_on_xⱼ) · (n_t/n) · ΔImpurity_t
```

где:
- `n_t` - количество примеров в узле t
- `n` - общее количество примеров
- `ΔImpurity_t` - уменьшение impurity при разбиении

**Нормализованная важность:**

```
Importance_norm(xⱼ) = Importance(xⱼ) / Σⱼ Importance(xⱼ)
```

### 7.2 Permutation Importance

**Алгоритм:**

```
1. Baseline_score = score(model, X_valid, y_valid)
2. Для каждого признака j:
   a) X_permuted = X_valid.copy()
   b) Перемешать значения X_permuted[:, j]
   c) Permuted_score = score(model, X_permuted, y_valid)
   d) Importance(j) = Baseline_score - Permuted_score
```

---

## 8. КОРРЕЛЯЦИОННЫЙ АНАЛИЗ

### 8.1 Pearson Correlation

```
ρ(X,Y) = Cov(X,Y) / (σₓ·σᵧ)

где:
Cov(X,Y) = E[(X - μₓ)(Y - μᵧ)]
```

**Интерпретация:**
- ρ = 1: сильная положительная корреляция
- ρ = 0: нет линейной корреляции
- ρ = -1: сильная отрицательная корреляция

### 8.2 Spearman Correlation

```
ρₛ = 1 - (6Σdᵢ²) / (n(n² - 1))
```

где:
- `dᵢ` - разность рангов
- Используется для нелинейных монотонных связей

---

## 9. СТРАТЕГИЯ ОБУЧЕНИЯ

### 9.1 Train-Test Split

```
Data ────┬───> Train Set (80%)
         │     │
         │     ├───> Обучение модели
         │     └───> Cross-Validation
         │
         └───> Test Set (20%)
               └───> Финальная оценка
```

**Стратифицированное разбиение** (если применимо):
- Сохраняет распределение целевой переменной

### 9.2 Hyperparameter Tuning

**Grid Search:**

```
best_params = argmax_{params} CV_Score(model(params))
```

**Random Search:**

```
Для i = 1 to n_iter:
    params_i = sample_random(param_distributions)
    score_i = CV_Score(model(params_i))
best_params = argmax_{i} score_i
```

---

## 10. ВИЗУАЛИЗАЦИЯ

### 10.1 Географическая визуализация

**Choropleth Map:**
- Цветовое кодирование по значению биоразнообразия
- Интерактивные элементы (hover, zoom)
- Легенда и цветовая шкала

**Инструменты:**
- `geopandas` - работа с геоданными
- `plotly.express` - интерактивные карты
- `folium` - веб-карты

### 10.2 Статистические графики

1. **Distribution Plots**
   - Гистограммы
   - Box plots
   - Violin plots

2. **Correlation Plots**
   - Heatmap корреляционной матрицы
   - Scatter plots

3. **Model Comparison**
   - Bar charts метрик
   - Actual vs Predicted plots

---

## 11. РЕКОМЕНДАЦИИ ПО РЕАЛИЗАЦИИ

### 11.1 Порядок выполнения

1. **Загрузка и первичный анализ данных**
   - Проверка структуры
   - Анализ пропусков
   - Базовая статистика

2. **Предобработка**
   - Pivot таблица по индикаторам
   - Создание синтетических признаков
   - Обработка выбросов
   - Нормализация

3. **EDA**
   - Визуализация распределений
   - Корреляционный анализ
   - Географическое распределение

4. **Моделирование**
   - Обучение минимум 3 моделей
   - Подбор гиперпараметров
   - Cross-validation

5. **Оценка**
   - Сравнение метрик
   - Анализ важности признаков
   - Выбор лучшей модели

6. **Визуализация результатов**
   - Карты предсказаний
   - Графики ошибок
   - Feature importance plots

7. **Отчет**
   - Выводы
   - Рекомендации
   - Ограничения

### 11.2 Ключевые библиотеки

```python
# Data processing
import pandas as pd
import numpy as np

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

from xgboost import XGBRegressor
from catboost import CatBoostRegressor

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

# Geo processing
import geopandas as gpd
import pycountry
```

---

## 12. ОЖИДАЕМЫЕ РЕЗУЛЬТАТЫ

### 12.1 Количественные показатели

- **R² > 0.7** для лучшей модели
- **RMSE < 20% от среднего значения** целевой переменной
- **Cross-Validation R² в пределах ±0.05** от Test R²

### 12.2 Качественные результаты

1. **Выявление ключевых факторов:**
   - Топ-5 признаков с наибольшим влиянием
   - Направление и сила влияния

2. **Географическая визуализация:**
   - Карта распределения биоразнообразия
   - Карта предсказаний модели
   - Карта ошибок предсказаний

3. **Аналитический отчет:**
   - Описание данных и методологии
   - Сравнение моделей
   - Интерпретация результатов
   - Рекомендации по сохранению биоразнообразия

---

## 13. ОГРАНИЧЕНИЯ И ДОПУЩЕНИЯ

### 13.1 Данные

- Синтетические климатические признаки
- Ограниченный временной период (2024 год)
- Потенциальные пропуски данных по некоторым странам

### 13.2 Модели

- Предполагается линейная или монотонная зависимость для некоторых моделей
- Не учитываются временные тренды (cross-sectional analysis)
- Корреляция не означает причинность

### 13.3 Валидация

- Географическая кластеризация не учитывается в train-test split
- Экстраполяция за пределы наблюдаемых значений может быть неточной

---

## ЗАКЛЮЧЕНИЕ

Данная архитектура обеспечивает:

✓ Воспроизводимость результатов  
✓ Модульность и расширяемость  
✓ Математическую строгость  
✓ Интерпретируемость моделей  
✓ Практическую применимость  

Данная лабораторная работа позволяет не только построить прогнозную модель, но и получить ценные инсайты о факторах, влияющих на биоразнообразие, что может быть использовано для принятия решений в области экологии и природоохранной деятельности.